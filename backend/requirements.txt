fastapi
uvicorn[standard]
python-dotenv
pydantic-settings

# --- LlamaIndex and Google AI Dependencies (Attempting Compatibility) ---

# Pin google-generativeai to the range required by embeddings-google
google-generativeai>=0.5.2,<0.6.0

# Keep the latest embeddings-google which requires the above range
llama-index-embeddings-google==0.3.1

# Downgrade llms-gemini to a version potentially compatible with google-generativeai 0.5.x
# Update: Try 0.3.1 which requires google-generativeai>=0.5.0,<0.6.0, aligning with embeddings
llama-index-llms-gemini==0.3.1

# Keep core llama-index relatively recent, but allow flexibility
# Let's use versions compatible with the older Gemini components if possible
# Update: embeddings-google requires >=0.12.0
llama-index>=0.12.0,<0.13.0 # Adjusted range for embeddings-google compatibility
llama-index-core>=0.12.0,<0.13.0

# Add other specific llama-index-* integrations if needed, without strict pins initially
llama-index-readers-file
llama-index-vector-stores-chroma

# --- Other Dependencies ---
chromadb>=0.4.0

# --- Testing Dependencies ---
pytest
httpx